#!/usr/bin/env python3
"""
SLOæ„ŸçŸ¥åŠ¨æ€èµ„æºè°ƒæ•´ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ï¼š
1. è·å–SGLangè¿è¡Œè¿‡ç¨‹ä¸­çš„çœŸå®metrics
2. åº”ç”¨è®ºæ–‡ç¬¬5èŠ‚çš„SLO-aware adjusting algorithm
3. å®ç°åŠ¨æ€èµ„æºè°ƒæ•´

ä½¿ç”¨æ–¹æ³•:
python examples/semi_pd/slo_aware_example.py --model-path meta-llama/Llama-3.1-8B-Instruct
"""

import argparse
import asyncio
import logging
import time
from typing import Dict, List

import numpy as np

from sglang.semi_pd.metrics_collector import SemiPDMetricsCollector, SystemMetrics
from sglang.semi_pd.metrics_integration import MetricsAggregator
from sglang.semi_pd.process_rotation_manager import ProcessRotationManager, SMAllocation
from sglang.semi_pd.slo_algorithm import SLOConstraints, SLOAwareResourceController
from sglang.semi_pd.utils import InstanceRole
from sglang.srt.server_args import ServerArgs, SemiPDPortArgs

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class SLOAwareDemo:
    """SLOæ„ŸçŸ¥åŠ¨æ€èµ„æºè°ƒæ•´æ¼”ç¤º"""
    
    def __init__(self, args):
        self.args = args
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.setup_components()
        
    def setup_components(self):
        """è®¾ç½®ç»„ä»¶"""
        logger.info("Setting up SLO-aware demo components...")
        
        # æœåŠ¡å™¨å‚æ•°
        self.server_args = ServerArgs()
        self.server_args.model_path = self.args.model_path
        self.server_args.enable_semi_pd = True
        
        # ç«¯å£å‚æ•°
        self.port_args = SemiPDPortArgs()
        self.port_args.host = "127.0.0.1"
        self.port_args.port = 30000
        
        # SLOçº¦æŸ
        self.slo_constraints = SLOConstraints(
            ttft_target_ms=self.args.ttft_target,
            tpot_target_ms=self.args.tpot_target,
            ttft_percentile=95.0,
            tpot_percentile=95.0,
        )
        
        # åˆå§‹èµ„æºåˆ†é…
        self.initial_allocation = SMAllocation(
            prefill_percentage=self.args.initial_prefill_sm,
            decode_percentage=self.args.initial_decode_sm,
        )
        
        # è¿›ç¨‹è½®æ¢ç®¡ç†å™¨
        self.process_rotation_manager = ProcessRotationManager(
            server_args=self.server_args,
            port_args=self.port_args,
            initial_sm_allocation=self.initial_allocation,
            gpu_id=0,
            tp_rank=0,
        )
        
        # Metricsæ”¶é›†å™¨
        self.prefill_metrics_collector = SemiPDMetricsCollector(window_size_seconds=30.0)
        self.decode_metrics_collector = SemiPDMetricsCollector(window_size_seconds=30.0)
        self.metrics_aggregator = MetricsAggregator()
        
        # SLOæ„ŸçŸ¥èµ„æºæ§åˆ¶å™¨
        self.slo_controller = SLOAwareResourceController(
            slo_constraints=self.slo_constraints,
            metrics_collector=self.prefill_metrics_collector,  # ä½¿ç”¨prefillä½œä¸ºä¸»è¦æ”¶é›†å™¨
            process_rotation_manager=self.process_rotation_manager,
            monitoring_interval=self.args.monitoring_interval,
        )
        
        logger.info("Components setup completed")
        
    def simulate_real_workload(self):
        """æ¨¡æ‹ŸçœŸå®å·¥ä½œè´Ÿè½½"""
        logger.info("Starting real workload simulation...")
        
        request_id_counter = 0
        
        try:
            for cycle in range(self.args.simulation_cycles):
                logger.info(f"Simulation cycle {cycle + 1}/{self.args.simulation_cycles}")
                
                # æ¨¡æ‹Ÿè¯·æ±‚åˆ°è¾¾å’Œå¤„ç†
                self._simulate_request_processing(cycle, request_id_counter)
                
                # æ¨¡æ‹Ÿç³»ç»ŸæŒ‡æ ‡
                self._simulate_system_metrics(cycle)
                
                # æ›´æ–°èšåˆæŒ‡æ ‡
                self._update_aggregated_metrics()
                
                # æ˜¾ç¤ºå½“å‰çŠ¶æ€
                if cycle % 5 == 0:
                    self._display_metrics_and_slo_status()
                    
                request_id_counter += 20  # æ¯ä¸ªå‘¨æœŸ20ä¸ªè¯·æ±‚
                
                # ç­‰å¾…ä¸‹ä¸€ä¸ªå‘¨æœŸ
                time.sleep(self.args.cycle_interval)
                
        except KeyboardInterrupt:
            logger.info("Simulation interrupted by user")
        except Exception as e:
            logger.error(f"Error during simulation: {e}")
            
    def _simulate_request_processing(self, cycle: int, base_request_id: int):
        """æ¨¡æ‹Ÿè¯·æ±‚å¤„ç†è¿‡ç¨‹"""
        # æ¨¡æ‹Ÿä¸åŒè´Ÿè½½æ¨¡å¼
        if cycle < 10:
            # è½»è´Ÿè½½é˜¶æ®µ
            num_requests = 5 + (cycle % 3)
            avg_input_length = 512
            avg_output_length = 128
        elif cycle < 20:
            # ä¸­ç­‰è´Ÿè½½é˜¶æ®µ
            num_requests = 10 + (cycle % 5)
            avg_input_length = 1024
            avg_output_length = 256
        else:
            # é«˜è´Ÿè½½é˜¶æ®µï¼ˆå¯èƒ½è¿åSLOï¼‰
            num_requests = 15 + (cycle % 7)
            avg_input_length = 2048
            avg_output_length = 512
            
        current_time = time.time()
        
        # æ¨¡æ‹Ÿè¯·æ±‚å¤„ç†æµç¨‹
        for i in range(num_requests):
            request_id = f"req_{base_request_id + i}"
            
            # éšæœºåŒ–è¾“å…¥è¾“å‡ºé•¿åº¦
            input_length = max(100, int(np.random.normal(avg_input_length, avg_input_length * 0.2)))
            output_length = max(50, int(np.random.normal(avg_output_length, avg_output_length * 0.3)))
            
            # æ¨¡æ‹Ÿè¯·æ±‚åˆ°è¾¾
            self.prefill_metrics_collector.record_request_arrival(request_id, input_length)
            
            # æ¨¡æ‹Ÿprefillå¤„ç†
            prefill_delay = self._calculate_prefill_delay(input_length, cycle)
            time.sleep(prefill_delay / 1000.0)  # è½¬æ¢ä¸ºç§’
            
            self.prefill_metrics_collector.record_prefill_start(request_id)
            self.prefill_metrics_collector.record_first_token(request_id)
            self.prefill_metrics_collector.record_prefill_end(request_id)
            
            # æ¨¡æ‹Ÿdecodeå¤„ç†
            decode_delay = self._calculate_decode_delay(output_length, cycle)
            time.sleep(decode_delay / 1000.0)  # è½¬æ¢ä¸ºç§’
            
            self.decode_metrics_collector.record_decode_start(request_id)
            
            # æ¨¡æ‹Ÿç¼“å­˜å‘½ä¸­
            cached_tokens = int(input_length * np.random.uniform(0.1, 0.4))
            
            # å®Œæˆè¯·æ±‚
            self.prefill_metrics_collector.record_request_completion(
                request_id, output_length, cached_tokens, success=True
            )
            self.decode_metrics_collector.record_request_completion(
                request_id, output_length, cached_tokens, success=True
            )
            
    def _calculate_prefill_delay(self, input_length: int, cycle: int) -> float:
        """è®¡ç®—prefillå»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰"""
        # åŸºç¡€å»¶è¿Ÿ + é•¿åº¦ç›¸å…³å»¶è¿Ÿ + è´Ÿè½½ç›¸å…³å»¶è¿Ÿ
        base_delay = 50.0
        length_delay = input_length * 0.05  # æ¯ä¸ªtoken 0.05ms
        load_delay = cycle * 2.0  # éšç€å‘¨æœŸå¢åŠ è´Ÿè½½
        
        # æ·»åŠ ä¸€äº›éšæœºæ€§
        noise = np.random.normal(0, 10.0)
        
        return max(20.0, base_delay + length_delay + load_delay + noise)
        
    def _calculate_decode_delay(self, output_length: int, cycle: int) -> float:
        """è®¡ç®—decodeå»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰"""
        # æ¯ä¸ªtokençš„å»¶è¿Ÿ
        per_token_delay = 15.0 + cycle * 0.5  # éšç€å‘¨æœŸå¢åŠ å»¶è¿Ÿ
        
        # æ·»åŠ ä¸€äº›éšæœºæ€§
        noise = np.random.normal(0, 2.0)
        
        return max(10.0, output_length * (per_token_delay + noise))
        
    def _simulate_system_metrics(self, cycle: int):
        """æ¨¡æ‹Ÿç³»ç»ŸæŒ‡æ ‡"""
        current_time = time.time()
        
        # æ¨¡æ‹Ÿé˜Ÿåˆ—é•¿åº¦ï¼ˆéšè´Ÿè½½å¢åŠ ï¼‰
        base_queue_length = min(50, cycle * 2)
        prefill_queue = max(0, int(np.random.normal(base_queue_length, base_queue_length * 0.3)))
        decode_queue = max(0, int(np.random.normal(base_queue_length * 1.5, base_queue_length * 0.4)))
        
        # æ¨¡æ‹Ÿåˆ©ç”¨ç‡
        base_utilization = min(0.9, cycle * 0.03)
        prefill_util = max(0.1, min(1.0, np.random.normal(base_utilization, 0.1)))
        decode_util = max(0.1, min(1.0, np.random.normal(base_utilization * 1.2, 0.1)))
        
        # æ¨¡æ‹Ÿååé‡
        prefill_throughput = max(100, 2000 - cycle * 30)
        decode_throughput = max(200, 3000 - cycle * 40)
        
        # æ¨¡æ‹Ÿç¼“å­˜å‘½ä¸­ç‡
        cache_hit_rate = max(0.1, min(0.8, 0.6 - cycle * 0.01))
        
        # è®°å½•prefillç³»ç»ŸæŒ‡æ ‡
        prefill_system_metrics = SystemMetrics(
            timestamp=current_time,
            prefill_queue_length=prefill_queue,
            prefill_running_requests=min(20, prefill_queue + 5),
            prefill_utilization=prefill_util,
            prefill_throughput=prefill_throughput,
            cache_hit_rate=cache_hit_rate,
        )
        
        # è®°å½•decodeç³»ç»ŸæŒ‡æ ‡
        decode_system_metrics = SystemMetrics(
            timestamp=current_time,
            decode_queue_length=decode_queue,
            decode_running_requests=min(30, decode_queue + 8),
            decode_utilization=decode_util,
            decode_throughput=decode_throughput,
            cache_hit_rate=cache_hit_rate,
        )
        
        self.prefill_metrics_collector.record_system_metrics(prefill_system_metrics)
        self.decode_metrics_collector.record_system_metrics(decode_system_metrics)
        
    def _update_aggregated_metrics(self):
        """æ›´æ–°èšåˆæŒ‡æ ‡"""
        prefill_metrics = self.prefill_metrics_collector.get_real_time_metrics()
        decode_metrics = self.decode_metrics_collector.get_real_time_metrics()
        
        self.metrics_aggregator.update_prefill_metrics(prefill_metrics)
        self.metrics_aggregator.update_decode_metrics(decode_metrics)
        
    def _display_metrics_and_slo_status(self):
        """æ˜¾ç¤ºæŒ‡æ ‡å’ŒSLOçŠ¶æ€"""
        logger.info("=== Current Metrics & SLO Status ===")
        
        try:
            # è·å–èšåˆæŒ‡æ ‡
            aggregated_metrics = self.metrics_aggregator.get_aggregated_metrics()
            
            if aggregated_metrics:
                logger.info(f"TTFT P95: {aggregated_metrics.get('ttft_p95_ms', 0):.1f}ms "
                           f"(Target: {self.slo_constraints.ttft_target_ms}ms)")
                logger.info(f"TPOT P95: {aggregated_metrics.get('tpot_p95_ms', 0):.1f}ms "
                           f"(Target: {self.slo_constraints.tpot_target_ms}ms)")
                
                # æ£€æŸ¥SLOè¿å
                ttft_violation = aggregated_metrics.get('ttft_p95_ms', 0) > self.slo_constraints.ttft_target_ms
                tpot_violation = aggregated_metrics.get('tpot_p95_ms', 0) > self.slo_constraints.tpot_target_ms
                
                if ttft_violation or tpot_violation:
                    logger.warning("ğŸš¨ SLO VIOLATION DETECTED!")
                    if ttft_violation:
                        logger.warning(f"  - TTFT violation: {aggregated_metrics.get('ttft_p95_ms', 0):.1f}ms > {self.slo_constraints.ttft_target_ms}ms")
                    if tpot_violation:
                        logger.warning(f"  - TPOT violation: {aggregated_metrics.get('tpot_p95_ms', 0):.1f}ms > {self.slo_constraints.tpot_target_ms}ms")
                else:
                    logger.info("âœ… SLO constraints satisfied")
                    
                logger.info(f"Queue lengths - Prefill: {aggregated_metrics.get('prefill_queue_length', 0)}, "
                           f"Decode: {aggregated_metrics.get('decode_queue_length', 0)}")
                logger.info(f"Utilization - Prefill: {aggregated_metrics.get('prefill_utilization', 0):.2%}, "
                           f"Decode: {aggregated_metrics.get('decode_utilization', 0):.2%}")
                logger.info(f"Throughput - Total: {aggregated_metrics.get('total_throughput', 0):.1f} tokens/s")
                
            # è·å–å½“å‰èµ„æºåˆ†é…
            status = self.process_rotation_manager.get_status()
            current_allocation = status["current_sm_allocation"]
            logger.info(f"Current SM allocation - Prefill: {current_allocation['prefill_percentage']}%, "
                       f"Decode: {current_allocation['decode_percentage']}%")
            
            # æ˜¾ç¤ºSLOæ§åˆ¶å™¨çŠ¶æ€
            controller_status = self.slo_controller.get_controller_status()
            stats = controller_status["statistics"]
            logger.info(f"SLO Controller - Adjustments: {stats['total_adjustments']}, "
                       f"Success rate: {stats['success_rate']:.1%}, "
                       f"Violations detected: {stats['slo_violations_detected']}")
                       
        except Exception as e:
            logger.error(f"Error displaying metrics: {e}")
            
        logger.info("=====================================")
        
    def run_demo(self):
        """è¿è¡Œæ¼”ç¤º"""
        logger.info("Starting SLO-aware dynamic resource adjustment demo")
        
        try:
            # å¯åŠ¨è¿›ç¨‹è½®æ¢ç®¡ç†å™¨ï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰
            logger.info("Starting process rotation manager...")
            # æ³¨æ„ï¼šåœ¨å®é™…ç¯å¢ƒä¸­éœ€è¦è°ƒç”¨ self.process_rotation_manager.start()
            
            # å¯åŠ¨SLOç›‘æ§
            logger.info("Starting SLO monitoring...")
            self.slo_controller.start_monitoring()
            
            # è¿è¡Œå·¥ä½œè´Ÿè½½æ¨¡æ‹Ÿ
            self.simulate_real_workload()
            
        except Exception as e:
            logger.error(f"Demo failed: {e}")
            raise
        finally:
            # æ¸…ç†
            logger.info("Stopping SLO monitoring...")
            self.slo_controller.stop_monitoring()
            
            logger.info("Stopping process rotation manager...")
            # æ³¨æ„ï¼šåœ¨å®é™…ç¯å¢ƒä¸­éœ€è¦è°ƒç”¨ self.process_rotation_manager.stop()
            
        logger.info("SLO-aware demo completed")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="SLOæ„ŸçŸ¥åŠ¨æ€èµ„æºè°ƒæ•´æ¼”ç¤º")
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument(
        "--model-path",
        type=str,
        default="meta-llama/Llama-3.1-8B-Instruct",
        help="æ¨¡å‹è·¯å¾„"
    )
    
    # SLOç›®æ ‡
    parser.add_argument(
        "--ttft-target",
        type=float,
        default=100.0,
        help="TTFTç›®æ ‡å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰"
    )
    parser.add_argument(
        "--tpot-target",
        type=float,
        default=50.0,
        help="TPOTç›®æ ‡å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰"
    )
    
    # åˆå§‹èµ„æºåˆ†é…
    parser.add_argument(
        "--initial-prefill-sm",
        type=int,
        default=70,
        help="åˆå§‹Prefill SMç™¾åˆ†æ¯”"
    )
    parser.add_argument(
        "--initial-decode-sm",
        type=int,
        default=30,
        help="åˆå§‹Decode SMç™¾åˆ†æ¯”"
    )
    
    # æ¨¡æ‹Ÿå‚æ•°
    parser.add_argument(
        "--simulation-cycles",
        type=int,
        default=50,
        help="æ¨¡æ‹Ÿå‘¨æœŸæ•°"
    )
    parser.add_argument(
        "--cycle-interval",
        type=float,
        default=2.0,
        help="å‘¨æœŸé—´éš”ï¼ˆç§’ï¼‰"
    )
    parser.add_argument(
        "--monitoring-interval",
        type=float,
        default=5.0,
        help="SLOç›‘æ§é—´éš”ï¼ˆç§’ï¼‰"
    )
    
    # æ—¥å¿—çº§åˆ«
    parser.add_argument(
        "--log-level",
        type=str,
        default="INFO",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        help="æ—¥å¿—çº§åˆ«"
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logging.getLogger().setLevel(getattr(logging, args.log_level))
    
    # è¿è¡Œæ¼”ç¤º
    demo = SLOAwareDemo(args)
    
    try:
        demo.run_demo()
    except KeyboardInterrupt:
        logger.info("Demo interrupted by user")
    except Exception as e:
        logger.error(f"Demo failed: {e}")
        return 1
        
    return 0


if __name__ == "__main__":
    exit(main())